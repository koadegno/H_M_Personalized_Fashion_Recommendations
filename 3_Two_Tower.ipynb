{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Two Tower Architecture\n",
    "This model is based on the two-tower architecture\n",
    "The two towers are used to learn representations of both the user and the item. The two-tower model is based on queries and the candidate they both shared a low-dimensional vector space. In our case, a query is customer and its transactions features and the candidate is the articles.\n",
    "\n",
    "I will try to use mlflow to keep track of experiments (and improve myself with this tool).\n",
    "\n",
    "\n",
    "\n",
    "![Alt text](https://miro.medium.com/v2/resize:fit:420/1*JbK2gjfLC4IFoM6AVWLaUQ.png)\n",
    "\n",
    "![Alt text](https://miro.medium.com/v2/resize:fit:420/format:webp/0*aJHT3_bGIvERfhaY)\n",
    "\n",
    "[image source](https://medium.com/smartnews-inc/user-behavior-sequence-for-items-recommendation-in-smartnews-ads-2376622f6192)\n",
    "\n",
    "\n",
    "\n",
    "Source: \n",
    "- https://medium.com/smartnews-inc/user-behavior-sequence-for-items-recommendation-in-smartnews-ads-2376622f6192\n",
    "- https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture?hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data and feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (105542, 25)\n",
      "Shape after:  (105542, 24)\n"
     ]
    }
   ],
   "source": [
    "articles_df = pd.read_csv(\"data/articles.csv\", encoding=\"utf-8\")\n",
    "print(\"Shape before: \", articles_df.shape)\n",
    "articles_df = preprocessing.preprocess_articles(articles_df)\n",
    "print(\"Shape after: \", articles_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (1371980, 7)\n",
      "Shape after:  (1356119, 5)\n"
     ]
    }
   ],
   "source": [
    "customers_df = pd.read_csv(\"data/customers.csv\", encoding=\"utf-8\")\n",
    "print(\"Shape before: \", customers_df.shape)\n",
    "customers_df = preprocessing.preprocess_customers(customers_df)\n",
    "print(\"Shape after: \", customers_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (31788324, 5)\n",
      "Shape after:  (31788324, 11)\n"
     ]
    }
   ],
   "source": [
    "transaction_df = pd.read_csv(\"data/transactions_train.csv\", encoding=\"utf-8\")\n",
    "print(\"Shape before: \", transaction_df.shape)\n",
    "transaction_df = preprocessing.preprocess_transactions(transaction_df)\n",
    "print(\"Shape after: \", transaction_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the three data sources to make the data compatible with out retrieval model.\n",
    "df = pd.merge(\n",
    "    pd.merge(\n",
    "        transaction_df[[\"article_id\", \"customer_id\", \"t_dat\", \"price\", \"month_sin\", \"month_cos\"]], articles_df[[\"article_id\", \"garment_group_name\", \"index_group_name\"]], on=\"article_id\", how=\"inner\"\n",
    "    ),\n",
    "    customers_df[[\"customer_id\", \"age\", \"club_member_status\", \"age_group\"]],\n",
    "    on=\"customer_id\",\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>age</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663713001</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>19-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663713001</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>24.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>19-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                        customer_id      t_dat  \\\n",
       "0  663713001  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca... 2018-09-20   \n",
       "1  663713001  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca... 2018-09-24   \n",
       "\n",
       "      price  month_sin  month_cos garment_group_name index_group_name   age  \\\n",
       "0  0.050831  -0.866025       -0.5  Under-, Nightwear       Ladieswear  24.0   \n",
       "1  0.050831  -0.866025       -0.5  Under-, Nightwear       Ladieswear  24.0   \n",
       "\n",
       "  club_member_status age_group  \n",
       "0             ACTIVE     19-25  \n",
       "1             ACTIVE     19-25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31648066, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validate/Test split and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a3a152fdd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 2024\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id            0\n",
       "customer_id           0\n",
       "t_dat                 0\n",
       "price                 0\n",
       "month_sin             0\n",
       "month_cos             0\n",
       "garment_group_name    0\n",
       "index_group_name      0\n",
       "age                   0\n",
       "club_member_status    0\n",
       "age_group             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (28483259, 11)\n",
      "Validation shape:  (3164807, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape: \", train_df.shape)\n",
    "print(\"Validation shape: \", val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# class CachedDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.encoders = {}\n",
    "#         self.data = {}\n",
    "\n",
    "#         # Process each column based on its type\n",
    "#         for col in df.columns:\n",
    "#             # Get column data\n",
    "#             col_data = df[col].values\n",
    "\n",
    "#             # Handle different data types\n",
    "#             if pd.api.types.is_numeric_dtype(df[col]) or col in [\"article_id\"]:\n",
    "#                 # For numeric data, convert to float32\n",
    "#                 self.data[col] = torch.tensor(col_data.astype(np.float32))\n",
    "\n",
    "#             else:\n",
    "#                 print(\"Col: \", col)\n",
    "#                 # For categorical/string data, use label encoding\n",
    "#                 self.encoders[col] = LabelEncoder()\n",
    "#                 encoded_data = self.encoders[col].fit_transform(col_data)\n",
    "#                 self.data[col] = torch.tensor(encoded_data, dtype=torch.long)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(next(iter(self.data.values())))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {key: value[idx] for key, value in self.data.items()}\n",
    "\n",
    "#     def get_feature_dims(self):\n",
    "#         \"\"\"Return the number of unique values for each categorical feature\"\"\"\n",
    "#         feature_dims = {}\n",
    "#         for col, encoder in self.encoders.items():\n",
    "#             feature_dims[col] = len(encoder.classes_)\n",
    "#         return feature_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = {col: torch.tensor(df[col].values) if pd.api.types.is_numeric_dtype(df[col]) else df[col].values for col in df.columns}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.data.values())))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: value[idx] for key, value in self.data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle mixed-type datasets\n",
    "\n",
    "    Args:\n",
    "        batch (list): List of dictionaries from the dataset\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with tensors and arrays properly handled\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to collect data\n",
    "    collated_batch = {}\n",
    "\n",
    "    # Iterate through keys of the first item to get all column names\n",
    "    for key in batch[0].keys():\n",
    "        # Collect values for this key\n",
    "        values = [item[key] for item in batch]\n",
    "\n",
    "        # Check the type of the first value to determine how to process\n",
    "        if isinstance(values[0], torch.Tensor):\n",
    "            # If it's already a tensor, stack them\n",
    "            collated_batch[key] = torch.stack(values)\n",
    "        elif isinstance(values[0], np.ndarray):\n",
    "            # If it's a numpy array, convert to tensor or keep as array\n",
    "            if values[0].dtype in [np.float32, np.float64, np.int32, np.int64]:\n",
    "                collated_batch[key] = torch.tensor(values)\n",
    "            else:\n",
    "                collated_batch[key] = np.array(values)\n",
    "        else:\n",
    "            # For other types (like strings), keep as list or array\n",
    "            collated_batch[key] = np.array(values)\n",
    "\n",
    "    return collated_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': array(['800800004', '770211001'], dtype=object),\n",
       " 'customer_id': array(['7169c8c204f8e37131bb13f05b31a0786e70d6789fa72af320bf245d7e4ccf74',\n",
       "        '0c6a37c6008e0740828502652ab3c7120b68d27a26fee734a9dee0f121997924'],\n",
       "       dtype=object),\n",
       " 't_dat': array(['2020-02-14T00:00:00.000000000', '2019-06-29T00:00:00.000000000'],\n",
       "       dtype='datetime64[ns]'),\n",
       " 'price': tensor([0.0169, 0.0190], dtype=torch.float64),\n",
       " 'month_sin': tensor([0.5000, 0.5000], dtype=torch.float64),\n",
       " 'month_cos': tensor([ 0.8660, -0.8660], dtype=torch.float64),\n",
       " 'garment_group_name': array(['Jersey Fancy', 'Dresses Ladies'], dtype=object),\n",
       " 'index_group_name': array(['Ladieswear', 'Ladieswear'], dtype=object),\n",
       " 'age': tensor([38., 23.], dtype=torch.float64),\n",
       " 'club_member_status': array(['ACTIVE', 'ACTIVE'], dtype=object),\n",
       " 'age_group': ['36-45', '19-25']\n",
       " Categories (8, object): ['0-18' < '19-25' < '26-35' < '36-45' < '46-55' < '56-65' < '66-80' < '80+']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2048  # 2048\n",
    "train_dataset = CustomDataset(train_df)\n",
    "train_dataset[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = train_df[\"customer_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"article_id\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of garment group: 21\n",
      "Number of index group: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of garment group: {len(garment_group_list):,}\")\n",
    "print(f\"Number of index group: {len(index_group_list):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 28,483,259\n",
      "Number of users: 1,332,386\n",
      "Number of items: 104,011\n",
      "['Jersey Fancy', 'Dresses Ladies', 'Socks and Tights', 'Swimwear', 'Under-, Nightwear', 'Blouses', 'Trousers', 'Accessories', 'Knitwear', 'Trousers Denim', 'Jersey Basic', 'Outdoor', 'Shirts', 'Shoes', 'Unknown', 'Special Offers', 'Shorts', 'Skirts', 'Dressed', 'Woven/Jersey/Knitted mix Baby', 'Dresses/Skirts girls']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")\n",
    "print(garment_group_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Tower Model\n",
    "\n",
    "- Query model: Generates a query representation given user and transaction features.\n",
    "- Candidate model: Generates an item representation given item features.\n",
    "\n",
    "**Both models produce embeddings that live in the same embedding space.**\n",
    "\n",
    "\n",
    "For the query embedding I will use:\n",
    "- `customer_id`: ID of the customer.\n",
    "- `age`: age of the customer at the time of purchase.\n",
    "- `month_sin`, `month_cos`: time of year the purchase was made.\n",
    "\n",
    "For the candidate embedding I will use:\n",
    "- `article_id`: ID of the item.\n",
    "- `garment_group_name`: type of garment.\n",
    "- `index_group_name`: menswear/ladieswear etc.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringLookup:\n",
    "\n",
    "    def __init__(self, vocabulary: List[str], mask_token=None):\n",
    "        self.vocab = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "        self.vocab[\"<UNK>\"] = len(self.vocab)\n",
    "        self.mask_token = mask_token\n",
    "\n",
    "    def __call__(self, inputs: np.ndarray) -> torch.Tensor:\n",
    "        # Convert string inputs to indices\n",
    "        indices = [self.vocab.get(x, self.vocab[\"<UNK>\"]) for x in inputs]\n",
    "        return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "\n",
    "class StringEmbedding(nn.Module):\n",
    "    def __init__(self, user_id_list: List[str], embedding_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create the vocabulary space\n",
    "        self.string_lookup = StringLookup(user_id_list)\n",
    "\n",
    "        # The real embeddings\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(self.string_lookup), embedding_dim=embedding_dimension)\n",
    "\n",
    "    def forward(self, user_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # Convert user IDs to indices\n",
    "        return self.embedding(self.string_lookup(user_ids))\n",
    "\n",
    "    # def forward(self, user_ids):\n",
    "    #     user_indices = torch.tensor([self.user_to_index.get(user_id, self.user_to_index[\"<UNK>\"]) for user_id in user_ids], device=self.embedding.weight.device)\n",
    "    #     return self.embedding(user_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class QueryTower(nn.Module):\n",
    "\n",
    "    def __init__(self, user_id_list: List[str], embedding_dimension: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = StringEmbedding(user_id_list, embedding_dimension)\n",
    "        self.age_normalization = nn.BatchNorm1d(1)\n",
    "\n",
    "        self.dense_nn = nn.Sequential(nn.Linear(in_features=embedding_dimension + 3, out_features=embedding_dimension), nn.Dropout(0.2), nn.ReLU(), nn.Linear(embedding_dimension, embedding_dimension))\n",
    "\n",
    "    def forward(self, inputs: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        user_embedding = self.user_embedding(inputs[\"customer_id\"])\n",
    "        normalized_age = self.age_normalization(inputs[\"age\"].float().unsqueeze(1))\n",
    "        month_sin = inputs[\"month_sin\"].float().unsqueeze(1)\n",
    "        month_cos = inputs[\"month_cos\"].float().unsqueeze(1)\n",
    "\n",
    "        concatenated_inputs = torch.cat([user_embedding, normalized_age, month_sin, month_cos], dim=1)\n",
    "\n",
    "        outputs = self.dense_nn(concatenated_inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QueryTower(user_id_list, 128)(train_dataset[0:2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The candidate model is very similar to the query model.\n",
    "\n",
    "it has two categorical features which will be one-hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(nn.Module):\n",
    "\n",
    "    def __init__(self, item_id_list: List[str], garment_group_list: List[str], index_group_list: List[str], embedding_dimension: int):\n",
    "        super().__init__()\n",
    "        self.item_embedding = StringEmbedding(item_id_list, embedding_dimension)\n",
    "\n",
    "        # Garment group setup\n",
    "        self.garment_group_lookup = StringLookup(vocabulary=garment_group_list)\n",
    "        self.garment_group_size = len(garment_group_list)\n",
    "\n",
    "        # Index group setup\n",
    "        self.index_group_lookup = StringLookup(vocabulary=index_group_list)\n",
    "        self.index_group_size = len(index_group_list)\n",
    "\n",
    "        input_dim = embedding_dimension + self.garment_group_size + self.index_group_size\n",
    "        self.dense_nn = nn.Sequential(nn.Linear(input_dim, embedding_dimension), nn.Dropout(0.2), nn.ReLU(), nn.Linear(embedding_dimension, embedding_dimension))\n",
    "\n",
    "    def forward(self, inputs: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "\n",
    "        # Convert article_id strings to embeddings\n",
    "        item_embedding = self.item_embedding(inputs[\"article_id\"])\n",
    "\n",
    "        garment_indices = self.garment_group_lookup(inputs[\"garment_group_name\"])\n",
    "        garment_one_hot = torch.zeros((garment_indices.size(0), self.garment_group_size), dtype=torch.float)\n",
    "        garment_one_hot.scatter_(1, garment_indices.unsqueeze(1), 1.0)\n",
    "\n",
    "        # Convert index group strings to one-hot encodings\n",
    "        index_indices = self.index_group_lookup(inputs[\"index_group_name\"])\n",
    "        index_one_hot = torch.zeros((index_indices.size(0), self.index_group_size), dtype=torch.float)\n",
    "        index_one_hot.scatter_(1, index_indices.unsqueeze(1), 1.0)\n",
    "\n",
    "        # Concatenate all features\n",
    "        concatenated = torch.cat([item_embedding, garment_one_hot, index_one_hot], dim=1)\n",
    "\n",
    "        outputs = self.dense_nn(concatenated)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItemTower(item_id_list, garment_group_list, index_group_list, 128)(train_dataset[0:2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of unique items\n",
    "unique_items_df = train_df.drop_duplicates(\"article_id\")[[\"article_id\", \"garment_group_name\", \"index_group_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items_df[\"article_id\"] = unique_items_df[\"article_id\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items_dataset = CustomDataset(unique_items_df)\n",
    "unique_items_loader = DataLoader(unique_items_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# Train and evaluate\n",
    "# train_and_evaluate(model=model, train_loader=train_loader, val_loader=val_loader, unique_items_loader=unique_items_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': tensor([800800004, 770211001]),\n",
       " 'garment_group_name': array(['Jersey Fancy', 'Dresses Ladies'], dtype=object),\n",
       " 'index_group_name': array(['Ladieswear', 'Ladieswear'], dtype=object)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items_dataset[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, query_tower: nn.Module, item_tower: nn.Module):\n",
    "        super().__init__()\n",
    "        self.query_tower = query_tower\n",
    "        self.item_tower = item_tower\n",
    "\n",
    "    def forward(self, batch: Dict) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        query_embeddings = self.query_tower(batch)\n",
    "        item_embeddings = self.item_tower(batch)\n",
    "\n",
    "        # Normalize embeddings\n",
    "        query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
    "        item_embeddings = F.normalize(item_embeddings, p=2, dim=1)\n",
    "\n",
    "        return query_embeddings, item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_100_accuracy(model, validation_loader, candidate_embeddings):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user_ids, true_item_ids in validation_loader:\n",
    "            # Compute user embeddings\n",
    "            user_embeddings, _ = model(user_ids)\n",
    "\n",
    "            # Compute similarity scores with candidate items\n",
    "            scores = torch.matmul(user_embeddings, candidate_embeddings.t())\n",
    "\n",
    "            # Get top 100 items for each user\n",
    "            _, top_k_indices = torch.topk(scores, k=100)\n",
    "\n",
    "            # Check if true item is in top 100 predictions\n",
    "            for i, true_item_id in enumerate(true_item_ids):\n",
    "                if true_item_id in top_k_indices[i]:\n",
    "                    correct_predictions += 1\n",
    "                total_predictions += 1\n",
    "\n",
    "    top_100_accuracy = correct_predictions / total_predictions\n",
    "    return top_100_accuracy\n",
    "\n",
    "\n",
    "def compute_loss(user_embeddings, item_embeddings, lambda_reg=1e-6):\n",
    "    # Compute similarity between query and item embeddings\n",
    "    similarity = torch.matmul(user_embeddings, item_embeddings.t())  # [batch_size, num_candidates]\n",
    "\n",
    "    # For contrastive loss (LogSumExp)\n",
    "    epsilon = 1e-8\n",
    "    logits = similarity - similarity.diagonal().unsqueeze(1)\n",
    "    # logger.debug(\n",
    "    #     f\"Similarity: {similarity}\",\n",
    "    # )\n",
    "    # logger.debug(\n",
    "    #     f\"Logits: {logits}\",\n",
    "    # )\n",
    "\n",
    "    loss = torch.logsumexp(logits, dim=1).mean()\n",
    "\n",
    "    # Regularization\n",
    "    reg_loss = (user_embeddings.norm(2) ** 2 + item_embeddings.norm(2) ** 2) * lambda_reg\n",
    "    reg_loss = reg_loss.item()\n",
    "    return loss, reg_loss\n",
    "\n",
    "\n",
    "def compute_loss2(query_embeddings, candidates_embeddings):\n",
    "    \"\"\"\n",
    "    Computes a loss similar to TensorFlow's Factorized Top-K retrieval loss\n",
    "\n",
    "    Args:\n",
    "    - batch: Current batch of data\n",
    "    - candidates_embeddings: Precomputed embeddings for all candidate items\n",
    "\n",
    "    Returns:\n",
    "    - Loss value\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute similarity between query embeddings and all candidate embeddings\n",
    "    # This is similar to the top-k metric computation in TensorFlow\n",
    "    similarities = torch.matmul(query_embeddings, candidates_embeddings.t())\n",
    "\n",
    "    # Create labels (diagonal matrix representing positive pairs)\n",
    "    labels = torch.arange(len(similarities)).to(similarities.device)\n",
    "\n",
    "    # Cross entropy loss\n",
    "    loss = nn.functional.cross_entropy(similarities, labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_loss3(user_embeddings, item_embeddings):\n",
    "    # Compute similarity between query and item embeddings\n",
    "    # similarities = torch.matmul(user_embeddings, item_embeddings.t())  # [batch_size, num_candidates]\n",
    "    similarities = torch.nn.functional.cosine_similarity(user_embeddings.unsqueeze(1), item_embeddings.unsqueeze(0), dim=-1)\n",
    "\n",
    "    labels = torch.arange(len(similarities)).to(similarities.device)\n",
    "\n",
    "    # Cross-entropy loss\n",
    "    loss = torch.nn.functional.cross_entropy(input=similarities, target=labels, reduction=\"none\")\n",
    "\n",
    "    # logger.debug(\n",
    "    #     f\"Similarity: {similarity}\",\n",
    "    # )\n",
    "    # logger.debug(\n",
    "    #     f\"Logits: {logits}\",\n",
    "    # )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, temperature: float = None):\n",
    "        super(RetrievalLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, query_embeddings, item_embeddings):\n",
    "\n",
    "        # Calculate dot product (similarity scores) between query and candidates\n",
    "        similarities = torch.matmul(query_embeddings, item_embeddings.t())  # [batch_size, num_items]\n",
    "\n",
    "        if self.temperature is not None:\n",
    "            similarities /= self.temperature\n",
    "\n",
    "        num_queries = similarities.shape[0]\n",
    "        # num_candidates = similarities.shape[1]\n",
    "\n",
    "        labels = torch.eye(num_queries)  # [batch_size]\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss(reduce=\"none\")\n",
    "\n",
    "        loss = loss_fn(similarities, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_top_k(model: TwoTowerModel, val_loader: DataLoader, item_embeddings: torch.Tensor, item_ids: np.ndarray, k: int = 100, device: torch.device = None) -> float:\n",
    "    \"\"\"Evaluate the model using top-k accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    total_hits = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            # Get query embeddings\n",
    "            query_embeddings = model.query_tower(batch[\"query\"])\n",
    "            query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
    "\n",
    "            # Compute similarities with all items\n",
    "            similarities = torch.matmul(query_embeddings, item_embeddings.t())\n",
    "\n",
    "            # Get top-k items\n",
    "            _, top_k_indices = similarities.topk(k)\n",
    "\n",
    "            # Get actual item IDs that were purchased\n",
    "            actual_items = batch[\"candidate\"][\"article_id\"]\n",
    "\n",
    "            # Check if actual items are in top-k predictions\n",
    "            for actual_item, top_k_idx in zip(actual_items, top_k_indices):\n",
    "                predicted_items = item_ids[top_k_idx.cpu()]\n",
    "                if actual_item in predicted_items:\n",
    "                    total_hits += 1\n",
    "                total_samples += 1\n",
    "\n",
    "    return total_hits / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"log.log\")\n",
    "\n",
    "file_handler = logging.FileHandler(\"notebook.log\")\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "logger.addHandler(file_handler)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_candidates_embeddings(model: TwoTowerModel, item_dataloader):\n",
    "    \"\"\"\n",
    "    Precompute embeddings for all candidate items\n",
    "\n",
    "    Args:\n",
    "    - model: Two Tower model\n",
    "    - item_dataloader: DataLoader with unique items\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of candidate embeddings\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        candidate_embeddings = []\n",
    "        for batch in item_dataloader:\n",
    "            item_embeddings = model.item_tower(batch)\n",
    "            candidate_embeddings.append(item_embeddings)\n",
    "\n",
    "        return torch.cat(candidate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader: DataLoader, item_dataloader: DataLoader, model: TwoTowerModel, learning_rate: float, weight_decay: float, num_epochs: int):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    loss_history = []\n",
    "    reg_loss_history = []\n",
    "    print_every = 1000\n",
    "\n",
    "    # candidates_embeddings = prepare_candidates_embeddings(model, item_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_reg_losses = []\n",
    "\n",
    "        bformat = \"{l_bar}{bar}| {n_fmt}/{total_fmt} {rate_fmt}{postfix}\"\n",
    "        with tqdm(total=len(train_dataloader), bar_format=bformat) as pbar:\n",
    "\n",
    "            for batch_idx, train_batch in enumerate(train_dataloader):\n",
    "                # train_batch = train_batch.to(device)\n",
    "\n",
    "                # for key, val in train_batch.items():\n",
    "                #     if isinstance(val, torch.Tensor):\n",
    "                #         is_nan = torch.any(torch.isnan(val))\n",
    "                #         logger.debug(f\"Col (T) :{key} is Nan? {is_nan}\")\n",
    "                #     else:\n",
    "                #         if isinstance(val.dtype, np.dtypes.StrDType):\n",
    "                #             empty_mask = val == \"\"\n",
    "                #             is_nan = np.any(empty_mask)\n",
    "                #         elif isinstance(val.dtype, np.dtypes.DateTime64DType):\n",
    "                #             continue\n",
    "                #         else:\n",
    "                #             is_nan = np.isnan(val)\n",
    "                #         logger.debug(f\"Col (NP) :{key} is Nan? {is_nan}\")\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                query_embeddings, item_embeddings = model(train_batch)\n",
    "\n",
    "                # try:\n",
    "                #     assert not torch.any(torch.isnan(query_embeddings)), \"NaN values detected in query_embeddings!\"\n",
    "                # except:\n",
    "                #     logger.error(\"NaN values detected in query_embeddings!\")\n",
    "                #     raise ValueError(\"query_embeddings should not be NaN\")\n",
    "                # try:\n",
    "                #     assert not torch.any(torch.isnan(item_embeddings)), \"NaN values detected in item_embeddings!\"\n",
    "                # except:\n",
    "                #     logger.error(\"NaN values detected in item_embeddings!\")\n",
    "                #     raise ValueError(\"item_embeddings should not be NaN\")\n",
    "\n",
    "                # print(query_embeddings.cpu())\n",
    "                # train_loss, reg_loss = compute_loss(query_embeddings, candidates_embeddings)\n",
    "                # loss = train_loss + reg_loss\n",
    "\n",
    "                loss = compute_loss3(query_embeddings, item_embeddings)\n",
    "\n",
    "                # logger.debug(f\"Batch {batch_idx}, Loss: {train_loss.item()}\")\n",
    "                # logger.debug(f\"User Embeddings: {query_embeddings}\")\n",
    "                # logger.debug(f\"Item Embeddings: {item_embeddings}\")\n",
    "\n",
    "                # try:\n",
    "                #     assert not torch.any(torch.isnan(loss)), \"NaN values detected in train_loss!\"\n",
    "                # except:\n",
    "                #     logger.error(\"NaN values detected in train_loss!\")\n",
    "                #     raise ValueError(\"train_loss should not be NaN\")\n",
    "\n",
    "                loss.backward()\n",
    "                # for param in model.parameters():\n",
    "\n",
    "                #     if param.grad is not None:\n",
    "                #         logger.debug(f\"Max gradient for name - {param.names} - device {param.get_device()}- {param} : {param.grad.max()}\")\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "                # train_losses.append(train_loss.item())\n",
    "                # train_reg_losses.append(reg_loss)\n",
    "\n",
    "                pbar.set_description(f\"EPOCH: {epoch:02d} \")\n",
    "                pbar.set_postfix_str(\" LOSS: {:.4f} \".format(loss.item()))\n",
    "                pbar.update()\n",
    "\n",
    "                if batch_idx % print_every == 0:\n",
    "                    print(\"Training: Batch {0}/{1}. Loss of {2:.4f}\".format(batch_idx + 1, len(train_dataloader), loss.item()))\n",
    "\n",
    "        # Last batch values\n",
    "        print(\"Training: Batch {0}/{1}. Loss of {2:.4f}\".format(batch_idx + 1, len(train_dataloader), train_losses[-1]))\n",
    "\n",
    "        torch.save(model.state_dict(), f\"models/training/Epoch_n_{epoch + 1}.pkl\")\n",
    "\n",
    "        mean_train_losss = np.mean(train_losses)\n",
    "        # mean_train_reg_losss = np.mean(train_reg_losses)\n",
    "        loss_history.append(mean_train_losss)\n",
    "        # reg_loss_history.append(mean_train_reg_losss)\n",
    "\n",
    "        print(\"Epoch {0}/{1}. Average Loss of {2:.4f} -\".format(epoch + 1, num_epochs, mean_train_losss))\n",
    "\n",
    "    return model, loss_history, reg_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(train_dataloader: DataLoader, item_dataloader: DataLoader, model: TwoTowerModel, learning_rate: float, weight_decay: float, num_epochs: int):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    loss_history = []\n",
    "    reg_loss_history = []\n",
    "    print_every = 1000\n",
    "\n",
    "    retrieval_loss_fn = RetrievalLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        bformat = \"{l_bar}{bar}| {n_fmt}/{total_fmt} {rate_fmt}{postfix}\"\n",
    "        with tqdm(total=len(train_dataloader), bar_format=bformat) as pbar:\n",
    "\n",
    "            for batch_idx, train_batch in enumerate(train_dataloader):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                query_embeddings, item_embeddings = model(train_batch)\n",
    "\n",
    "                loss = retrieval_loss_fn(query_embeddings, item_embeddings)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "                pbar.set_description(f\"EPOCH: {epoch:02d} \")\n",
    "                pbar.set_postfix_str(\" LOSS: {:.4f} \".format(train_losses[-1]))\n",
    "                pbar.update()\n",
    "\n",
    "                if batch_idx % print_every == 0:\n",
    "                    print(\"Training: Batch {0}/{1}. Loss of {2:.4f}\".format(batch_idx + 1, len(train_dataloader), train_losses[-1]))\n",
    "\n",
    "        # Last batch values\n",
    "        print(\"Training: Batch {0}/{1}. Loss of {2:.4f}\".format(batch_idx + 1, len(train_dataloader), train_losses[-1]))\n",
    "\n",
    "        torch.save(model.state_dict(), f\"models/training/Epoch_n_{epoch + 1}.pkl\")\n",
    "\n",
    "        mean_train_losss = np.mean(train_losses)\n",
    "        loss_history.append(mean_train_losss)\n",
    "\n",
    "        print(\"Epoch {0}/{1}. Average Loss of {2:.4f} -\".format(epoch + 1, num_epochs, mean_train_losss))\n",
    "\n",
    "    return model, loss_history, reg_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoTowerModel(\n",
       "  (query_tower): QueryTower(\n",
       "    (user_embedding): StringEmbedding(\n",
       "      (embedding): Embedding(1332387, 16)\n",
       "    )\n",
       "    (age_normalization): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dense_nn): Sequential(\n",
       "      (0): Linear(in_features=19, out_features=16, bias=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (item_tower): ItemTower(\n",
       "    (item_embedding): StringEmbedding(\n",
       "      (embedding): Embedding(104012, 16)\n",
       "    )\n",
       "    (dense_nn): Sequential(\n",
       "      (0): Linear(in_features=42, out_features=16, bias=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = 16\n",
    "model = TwoTowerModel(\n",
    "    query_tower=QueryTower(user_id_list, embedding_dimension=embedding_dimension), item_tower=ItemTower(item_id_list, garment_group_list, index_group_list, embedding_dimension=embedding_dimension)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-3\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048  # 2048\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_df)\n",
    "val_dataset = CustomDataset(val_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=custom_collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :   0%|          | 1/13908  6.61s/it,  LOSS: 7.5845 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1/13908. Loss of 7.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :   7%|▋         | 1001/13908  3.09it/s,  LOSS: 7.3448 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1001/13908. Loss of 7.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  14%|█▍        | 2001/13908  3.15it/s,  LOSS: 7.2762 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 2001/13908. Loss of 7.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  22%|██▏       | 3001/13908  3.33it/s,  LOSS: 7.2789 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 3001/13908. Loss of 7.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  29%|██▉       | 4001/13908  3.24it/s,  LOSS: 7.2764 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 4001/13908. Loss of 7.2764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  36%|███▌      | 5001/13908  3.02it/s,  LOSS: 7.2486 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 5001/13908. Loss of 7.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  43%|████▎     | 6001/13908  3.39it/s,  LOSS: 7.2676 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 6001/13908. Loss of 7.2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  50%|█████     | 7001/13908  3.34it/s,  LOSS: 7.2508 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 7001/13908. Loss of 7.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  58%|█████▊    | 8001/13908  3.36it/s,  LOSS: 7.2447 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 8001/13908. Loss of 7.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  65%|██████▍   | 9001/13908  3.50it/s,  LOSS: 7.2565 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 9001/13908. Loss of 7.2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  72%|███████▏  | 10001/13908  3.09it/s,  LOSS: 7.2557 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 10001/13908. Loss of 7.2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  79%|███████▉  | 11001/13908  3.47it/s,  LOSS: 7.2327 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 11001/13908. Loss of 7.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  86%|████████▋ | 12001/13908  3.11it/s,  LOSS: 7.2424 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 12001/13908. Loss of 7.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 :  93%|█████████▎| 13001/13908  3.51it/s,  LOSS: 7.2400 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13001/13908. Loss of 7.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 00 : 100%|██████████| 13908/13908  3.13it/s,  LOSS: 7.0570 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13908/13908. Loss of 7.0570\n",
      "Epoch 1/5. Average Loss of 7.2692 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :   0%|          | 1/13908  2.67s/it,  LOSS: 7.2277 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1/13908. Loss of 7.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :   7%|▋         | 1001/13908  3.44it/s,  LOSS: 7.2350 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1001/13908. Loss of 7.2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  14%|█▍        | 2001/13908  3.22it/s,  LOSS: 7.2292 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 2001/13908. Loss of 7.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  22%|██▏       | 3001/13908  3.54it/s,  LOSS: 7.2119 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 3001/13908. Loss of 7.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  29%|██▉       | 4001/13908  3.19it/s,  LOSS: 7.2138 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 4001/13908. Loss of 7.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  36%|███▌      | 5001/13908  2.59it/s,  LOSS: 7.2282 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 5001/13908. Loss of 7.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  43%|████▎     | 6001/13908  3.24it/s,  LOSS: 7.2249 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 6001/13908. Loss of 7.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  50%|█████     | 7001/13908  3.13it/s,  LOSS: 7.2180 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 7001/13908. Loss of 7.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  58%|█████▊    | 8001/13908  3.43it/s,  LOSS: 7.2295 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 8001/13908. Loss of 7.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  65%|██████▍   | 9001/13908  3.32it/s,  LOSS: 7.2137 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 9001/13908. Loss of 7.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  72%|███████▏  | 10001/13908  2.77it/s,  LOSS: 7.2230 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 10001/13908. Loss of 7.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  79%|███████▉  | 11001/13908  3.52it/s,  LOSS: 7.2166 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 11001/13908. Loss of 7.2166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  86%|████████▋ | 12001/13908  3.12it/s,  LOSS: 7.2156 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 12001/13908. Loss of 7.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 :  93%|█████████▎| 13001/13908  3.31it/s,  LOSS: 7.2271 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13001/13908. Loss of 7.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 01 : 100%|██████████| 13908/13908  3.22it/s,  LOSS: 7.0622 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13908/13908. Loss of 7.0622\n",
      "Epoch 2/5. Average Loss of 7.2175 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :   0%|          | 1/13908  2.32s/it,  LOSS: 7.1884 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1/13908. Loss of 7.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :   7%|▋         | 1001/13908  3.43it/s,  LOSS: 7.2119 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1001/13908. Loss of 7.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  14%|█▍        | 2001/13908  2.60it/s,  LOSS: 7.2025 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 2001/13908. Loss of 7.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  22%|██▏       | 3001/13908  3.35it/s,  LOSS: 7.2016 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 3001/13908. Loss of 7.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  29%|██▉       | 4001/13908  3.17it/s,  LOSS: 7.2042 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 4001/13908. Loss of 7.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  36%|███▌      | 5001/13908  3.43it/s,  LOSS: 7.2068 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 5001/13908. Loss of 7.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  43%|████▎     | 6001/13908  3.28it/s,  LOSS: 7.1833 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 6001/13908. Loss of 7.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  50%|█████     | 7001/13908  2.61it/s,  LOSS: 7.2017 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 7001/13908. Loss of 7.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  58%|█████▊    | 8001/13908  3.57it/s,  LOSS: 7.2025 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 8001/13908. Loss of 7.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  65%|██████▍   | 9001/13908  3.18it/s,  LOSS: 7.2066 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 9001/13908. Loss of 7.2066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  72%|███████▏  | 10001/13908  3.38it/s,  LOSS: 7.2071 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 10001/13908. Loss of 7.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  79%|███████▉  | 11001/13908  3.31it/s,  LOSS: 7.2090 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 11001/13908. Loss of 7.2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  86%|████████▋ | 12001/13908  2.93it/s,  LOSS: 7.2280 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 12001/13908. Loss of 7.2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 :  93%|█████████▎| 13001/13908  3.44it/s,  LOSS: 7.2078 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13001/13908. Loss of 7.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 02 : 100%|██████████| 13908/13908  3.23it/s,  LOSS: 7.0202 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13908/13908. Loss of 7.0202\n",
      "Epoch 3/5. Average Loss of 7.2015 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :   0%|          | 1/13908  2.31s/it,  LOSS: 7.1965 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1/13908. Loss of 7.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :   7%|▋         | 1001/13908  3.21it/s,  LOSS: 7.1779 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1001/13908. Loss of 7.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  14%|█▍        | 2001/13908  3.43it/s,  LOSS: 7.1837 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 2001/13908. Loss of 7.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  22%|██▏       | 3001/13908  3.24it/s,  LOSS: 7.1893 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 3001/13908. Loss of 7.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  29%|██▉       | 4001/13908  2.62it/s,  LOSS: 7.1794 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 4001/13908. Loss of 7.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  36%|███▌      | 5001/13908  3.49it/s,  LOSS: 7.2014 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 5001/13908. Loss of 7.2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  43%|████▎     | 6001/13908  3.35it/s,  LOSS: 7.2053 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 6001/13908. Loss of 7.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  50%|█████     | 7001/13908  3.42it/s,  LOSS: 7.1844 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 7001/13908. Loss of 7.1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  58%|█████▊    | 8001/13908  3.34it/s,  LOSS: 7.2190 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 8001/13908. Loss of 7.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  65%|██████▍   | 9001/13908  2.76it/s,  LOSS: 7.1837 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 9001/13908. Loss of 7.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  72%|███████▏  | 10001/13908  3.37it/s,  LOSS: 7.1886 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 10001/13908. Loss of 7.1886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  79%|███████▉  | 11001/13908  3.12it/s,  LOSS: 7.1916 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 11001/13908. Loss of 7.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  86%|████████▋ | 12001/13908  3.54it/s,  LOSS: 7.2062 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 12001/13908. Loss of 7.2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 :  93%|█████████▎| 13001/13908  3.32it/s,  LOSS: 7.2114 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13001/13908. Loss of 7.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 03 : 100%|██████████| 13908/13908  3.22it/s,  LOSS: 7.0405 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13908/13908. Loss of 7.0405\n",
      "Epoch 4/5. Average Loss of 7.1937 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :   0%|          | 1/13908  2.29s/it,  LOSS: 7.1814 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1/13908. Loss of 7.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :   7%|▋         | 1001/13908  3.14it/s,  LOSS: 7.1834 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 1001/13908. Loss of 7.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  14%|█▍        | 2001/13908  3.34it/s,  LOSS: 7.1982 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 2001/13908. Loss of 7.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  22%|██▏       | 3001/13908  3.11it/s,  LOSS: 7.1926 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 3001/13908. Loss of 7.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  29%|██▉       | 4001/13908  2.88it/s,  LOSS: 7.1909 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 4001/13908. Loss of 7.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  36%|███▌      | 5001/13908  3.39it/s,  LOSS: 7.1832 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 5001/13908. Loss of 7.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  43%|████▎     | 6001/13908  3.21it/s,  LOSS: 7.2028 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 6001/13908. Loss of 7.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  50%|█████     | 7001/13908  3.44it/s,  LOSS: 7.1953 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 7001/13908. Loss of 7.1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  58%|█████▊    | 8001/13908  3.28it/s,  LOSS: 7.1900 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 8001/13908. Loss of 7.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  65%|██████▍   | 9001/13908  2.84it/s,  LOSS: 7.2064 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 9001/13908. Loss of 7.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  72%|███████▏  | 10001/13908  3.44it/s,  LOSS: 7.1876 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 10001/13908. Loss of 7.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  79%|███████▉  | 11001/13908  3.16it/s,  LOSS: 7.1978 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 11001/13908. Loss of 7.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  86%|████████▋ | 12001/13908  3.51it/s,  LOSS: 7.1917 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 12001/13908. Loss of 7.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 :  93%|█████████▎| 13001/13908  3.26it/s,  LOSS: 7.1972 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13001/13908. Loss of 7.1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH: 04 : 100%|██████████| 13908/13908  3.22it/s,  LOSS: 7.0184 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Batch 13908/13908. Loss of 7.0184\n",
      "Epoch 5/5. Average Loss of 7.1890 -\n"
     ]
    }
   ],
   "source": [
    "model, loss_history, reg_loss_history = train_model2(train_loader, unique_items_loader, model, learning_rate, weight_decay, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_history(loss_history, num_epochs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker=\"o\")\n",
    "    plt.title(\"Training Loss over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Average Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, num_epochs + 1))  # Set x-axis ticks to show each epoch\n",
    "\n",
    "    # Annotate the lowest loss point\n",
    "    min_loss = min(loss_history)\n",
    "    min_epoch = loss_history.index(min_loss) + 1\n",
    "    plt.annotate(\n",
    "        f\"Lowest: {min_loss:.4f}\",\n",
    "        xy=(min_epoch, min_loss),\n",
    "        xytext=(5, 5),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"yellow\", alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0\"),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss_history(loss_history, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_loss_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_loss_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m, in \u001b[0;36mplot_loss_history\u001b[1;34m(loss_history, num_epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_loss_history\u001b[39m(loss_history, num_epochs):\n\u001b[0;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss over Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Projects\\H_M_Personalized_Fashion_Recommendations\\venv\\lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3796\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3797\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3800\u001b[0m     )\n",
      "File \u001b[1;32me:\\Projects\\H_M_Personalized_Fashion_Recommendations\\venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32me:\\Projects\\H_M_Personalized_Fashion_Recommendations\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Projects\\H_M_Personalized_Fashion_Recommendations\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_history(reg_loss_history, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
